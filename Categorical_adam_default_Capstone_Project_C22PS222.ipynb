{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Information \n",
        "\n",
        "**badAI**\n",
        "\n",
        "This capstone project is built in the first place because after further discussion, our team gravitates more on the beauty industry because its a growing business with a lot of opportunities and room for growth. We are also interested in solving medically related problems within the scalp and help people identify it easier. So we are trying to tackle this side of the business, especially in the haircare and scalp world where information, knowledge, and extensive service is still very scarce.\n",
        "\n",
        "For this project, we use the dataset from google images because there is no dataset that contains the images that we need. The dataset contains 6 scalp problems that are alopecia areata, dandruff, folliculitis, psoriasis, seborrheic dermatitis, and tinea capitis and 1 dataset for healthy scalp.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GS1sHE3z3UUx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Environment Setup"
      ],
      "metadata": {
        "id": "AqMB7EfQ424x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import Libraries"
      ],
      "metadata": {
        "id": "5tPTROlS48uX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import os\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "VspDhbMd3VDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mount Drive"
      ],
      "metadata": {
        "id": "wv2hr0Ku48Bf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5tYLd2JOITl"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir('/content/gdrive/My Drive/Capstone-Dataset-C22-P222')\n",
        "root_path = '/content/gdrive/My Drive/Capstone-Dataset-C22-P222/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Assign Directories"
      ],
      "metadata": {
        "id": "imWKi9s15Xb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(root_path, 'train')\n",
        "validation_dir = os.path.join(root_path, 'validation')"
      ],
      "metadata": {
        "id": "as5uFsFZFrPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Augmentation"
      ],
      "metadata": {
        "id": "6q-JDrkd5jTA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8RD-TyYiQh-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1/255,\n",
        "                                   rotation_range=360,\n",
        "                                   shear_range=0.4,\n",
        "                                   horizontal_flip=True,\n",
        "                                   vertical_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "validation_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    shuffle=True,\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    color_mode='rgb',\n",
        "                                                    target_size=(150, 150))     \n",
        "\n",
        "validation_generator =  validation_datagen.flow_from_directory(validation_dir,\n",
        "                                                               shuffle=True,\n",
        "                                                               batch_size=20,\n",
        "                                                               color_mode='rgb',\n",
        "                                                               class_mode  = 'categorical',\n",
        "                                                               target_size = (150, 150))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Assign Transfer Learning (Inception V3)"
      ],
      "metadata": {
        "id": "qd-cEx3W5rF8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3Isg5Kxi0uW"
      },
      "outputs": [],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u89s2Illi7DW"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Assign Pre-Trained Model"
      ],
      "metadata": {
        "id": "VwGkNh8Z54Y1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLqtRRID4nuv"
      },
      "outputs": [],
      "source": [
        "def create_pre_trained_model(local_weights_file):\n",
        "  pre_trained_model = InceptionV3(input_shape = (150, 150, 3),\n",
        "                                  include_top = False, \n",
        "                                  weights = None) \n",
        "\n",
        "  pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "  for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  return pre_trained_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre_trained_model = create_pre_trained_model(local_weights_file)"
      ],
      "metadata": {
        "id": "SwG5XH3wGMli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def output_of_last_layer(pre_trained_model):\n",
        "  last_desired_layer = pre_trained_model.get_layer('mixed7')\n",
        "  print('last layer output shape: ', last_desired_layer.output_shape)\n",
        "  last_output = last_desired_layer.output\n",
        "  print('last layer output: ', last_output)\n",
        "\n",
        "  return last_output"
      ],
      "metadata": {
        "id": "k4jqcYaZGZLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_output = output_of_last_layer(pre_trained_model)"
      ],
      "metadata": {
        "id": "cIcsWI8z6v33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create Final Model"
      ],
      "metadata": {
        "id": "jkwfagIn5-h8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzSsB1w1Fr1L"
      },
      "outputs": [],
      "source": [
        "def create_final_model(pre_trained_model, last_output):\n",
        "  x = layers.Flatten()(last_output)\n",
        "\n",
        "  x = layers.Dense(1024, activation='relu')(x)\n",
        "  x = layers.Dropout(0.2)(x)\n",
        "  x = layers.Dense(7, activation='softmax')(x)       \n",
        "\n",
        "  model = Model(inputs=pre_trained_model.input, outputs=x)\n",
        "\n",
        "  model.compile(optimizer = 'adam', \n",
        "                loss = 'categorical_crossentropy',\n",
        "                metrics = ['accuracy'])\n",
        "  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRDHQG9MG188"
      },
      "outputs": [],
      "source": [
        "model = create_final_model(pre_trained_model, last_output)\n",
        "\n",
        "total_params = model.count_params()\n",
        "num_trainable_params = sum([w.shape.num_elements() for w in model.trainable_weights])\n",
        "\n",
        "print(f\"There are {total_params:,} total parameters in this model.\")\n",
        "print(f\"There are {num_trainable_params:,} trainable parameters in this model.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run The Model"
      ],
      "metadata": {
        "id": "9rVYmqpi6JEJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uthb5DxEJfeE"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_generator,\n",
        "                    validation_data = validation_generator,\n",
        "                    epochs = 50,\n",
        "                    verbose = 2,\n",
        "                    steps_per_epoch = train_generator.samples // train_generator.batch_size,\n",
        "                    validation_steps = validation_generator.samples // validation_generator.batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Accuracy and Loss Graph"
      ],
      "metadata": {
        "id": "NbbKtHCw6L8y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENiJNSMaYKM2"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing Image\n",
        "\n"
      ],
      "metadata": {
        "id": "iLdrZqju6LlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded=files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  root_path = '/content/gdrive/My Drive/Capstone-Dataset/'\n",
        "  path = root_path + fn\n",
        "  img = image.load_img(path, target_size=(150, 150))\n",
        "\n",
        "  # + \" (2)\"\n",
        "  \n",
        "  x=image.img_to_array(img)\n",
        "  x /= 255\n",
        "  x=np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "  \n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  \n",
        "  print(classes[0])\n",
        "  \n",
        "  if max([classes[0][0], classes[0][1], classes[0][2], classes[0][3], classes[0][4], classes[0][5], classes[0][6]]) == classes[0][0]:\n",
        "    print(fn + \" is alopecia_areata\")\n",
        "  elif max([classes[0][0], classes[0][1], classes[0][2], classes[0][3], classes[0][4], classes[0][5], classes[0][6]]) == classes[0][1]:\n",
        "    print(fn + \" is dandruff\")\n",
        "  elif max([classes[0][0], classes[0][1], classes[0][2], classes[0][3], classes[0][4], classes[0][5], classes[0][6]]) == classes[0][2]:\n",
        "    print(fn + \" is folliculitis\")\n",
        "  elif max([classes[0][0], classes[0][1], classes[0][2], classes[0][3], classes[0][4], classes[0][5], classes[0][6]]) == classes[0][3]:\n",
        "    print(fn + \" is healthy_scalp\")\n",
        "  elif max([classes[0][0], classes[0][1], classes[0][2], classes[0][3], classes[0][4], classes[0][5], classes[0][6]]) == classes[0][4]:\n",
        "    print(fn + \" is psoriasis\")\n",
        "  elif max([classes[0][0], classes[0][1], classes[0][2], classes[0][3], classes[0][4], classes[0][5], classes[0][6]]) == classes[0][5]:\n",
        "    print(fn + \" is seborrheic_dermatitis\")\n",
        "  elif max([classes[0][0], classes[0][1], classes[0][2], classes[0][3], classes[0][4], classes[0][5], classes[0][6]]) == classes[0][6]:\n",
        "    print(fn + \" is tinea_capitis\")"
      ],
      "metadata": {
        "id": "KcUwGD_2N_cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save the Model into .h5"
      ],
      "metadata": {
        "id": "sRsXYcDR6acB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('Categorical_Adam.h5')"
      ],
      "metadata": {
        "id": "GqfYfHTrPbsz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "RawCode-Categorical-adam_default-Capstone-Project-C22PS22",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}