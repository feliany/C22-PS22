{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5qLF6YvBaIK0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import os\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow_hub as hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5tYLd2JOITl",
        "outputId": "aa33bcdc-0e17-4355-857c-0a7083e25dfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir('/content/gdrive/My Drive/Capstone-Dataset')\n",
        "root_path = '/content/gdrive/My Drive/Capstone-Dataset/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(root_path, 'train')\n",
        "validation_dir = os.path.join(root_path, 'validation')"
      ],
      "metadata": {
        "id": "as5uFsFZFrPx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8RD-TyYiQh-",
        "outputId": "18a66b28-c503-42b9-fcf8-c3c145fd08bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1329 images belonging to 7 classes.\n",
            "Found 132 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1/255,\n",
        "                                   rotation_range=45,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "validation_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    shuffle=True,\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    color_mode='rgb',\n",
        "                                                    target_size=(150, 150))     \n",
        "\n",
        "validation_generator =  validation_datagen.flow_from_directory(validation_dir,\n",
        "                                                               shuffle=True,\n",
        "                                                               batch_size=20,\n",
        "                                                               color_mode='rgb',\n",
        "                                                               class_mode  = 'categorical',\n",
        "                                                               target_size = (150, 150))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3Isg5Kxi0uW",
        "outputId": "55bc6827-aecf-4dbb-f800-287be2313143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-03 15:08:07--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.161.128, 142.250.152.128, 74.125.132.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.161.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   231MB/s    in 0.4s    \n",
            "\n",
            "2022-06-03 15:08:07 (231 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "u89s2Illi7DW"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pre_trained_model(local_weights_file):\n",
        "  pre_trained_model = InceptionV3(input_shape = (150, 150, 3),\n",
        "                                  include_top = False, \n",
        "                                  weights = None) \n",
        "\n",
        "  pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "  for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  return pre_trained_model"
      ],
      "metadata": {
        "id": "5Pa-8bzBF6vY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_trained_model = create_pre_trained_model(local_weights_file)"
      ],
      "metadata": {
        "id": "SwG5XH3wGMli"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def output_of_last_layer(pre_trained_model):\n",
        "  last_desired_layer = pre_trained_model.get_layer('mixed7')\n",
        "  print('last layer output shape: ', last_desired_layer.output_shape)\n",
        "  last_output = last_desired_layer.output\n",
        "  print('last layer output: ', last_output)\n",
        "\n",
        "  return last_output"
      ],
      "metadata": {
        "id": "k4jqcYaZGZLP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_output = output_of_last_layer(pre_trained_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icLEI4A4GbLI",
        "outputId": "b7e5d742-9c37-46f6-c8ee-8d2082426a57"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n",
            "last layer output:  KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 768), dtype=tf.float32, name=None), name='mixed7/concat:0', description=\"created by layer 'mixed7'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zzSsB1w1Fr1L"
      },
      "outputs": [],
      "source": [
        "def create_final_model(pre_trained_model, last_output):\n",
        "  x = layers.Flatten()(last_output)\n",
        "\n",
        "  x = layers.Dense(1024, activation='relu')(x)\n",
        "  x = layers.Dropout(0.2)(x)\n",
        "  x = layers.Dense(7, activation='softmax')(x)       \n",
        "\n",
        "  model = Model(inputs=pre_trained_model.input, outputs=x)\n",
        "\n",
        "  model.compile(optimizer = 'adam', \n",
        "                loss = 'categorical_crossentropy',\n",
        "                metrics = ['accuracy'])\n",
        "  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRDHQG9MG188",
        "outputId": "0855f57b-080a-42dd-b974-8ee1536f1aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 74, 74, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 74, 74, 32)  96          ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 74, 74, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 72, 72, 32)   9216        ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 72, 72, 32)  96          ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 72, 72, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 72, 72, 64)   18432       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 72, 72, 64)  192         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 72, 72, 64)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 35, 35, 64)   0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 35, 35, 80)   5120        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 35, 35, 80)  240         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 35, 35, 80)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 33, 33, 192)  138240      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 33, 33, 192)  576        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 33, 33, 192)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 16, 16, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 96)   55296       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 16, 16, 48)  144         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 96)  288         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 16, 16, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 96)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 16, 16, 192)  0          ['max_pooling2d_1[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 64)   76800       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 16, 16, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 16, 16, 96)  288         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 32)  96          ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 16, 16, 64)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 48)  144         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 16, 16, 96)  288         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 16, 16, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 64)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 16, 16, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 16, 16, 96)  288         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 16, 16, 64)  192         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 16, 16, 64)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 16, 16, 48)  144         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 16, 16, 96)  288         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 16, 16, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 16, 16, 64)  192         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 16, 16, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 16, 16, 96)  288         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 16, 16, 64)  192         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 16, 16, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 16, 16, 96)  288         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 7, 7, 384)   1152        ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 7, 7, 96)    288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 7, 7, 384)    0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 7, 7, 128)   384         ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 7, 7, 128)   384         ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 7, 7, 128)   384         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 7, 7, 128)   384         ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 7, 7, 128)   384         ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 7, 7, 128)   384         ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 7, 7, 192)   576         ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 7, 7, 192)   576         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 7, 7, 192)   576         ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 7, 7, 192)   576         ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 7, 7, 160)   480         ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 7, 7, 160)   480         ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 7, 7, 160)   480         ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 7, 7, 160)   480         ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 7, 7, 160)   480         ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 7, 7, 160)   480         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 7, 7, 192)   576         ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 7, 7, 192)   576         ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 7, 7, 192)   576         ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 7, 7, 192)   576         ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 7, 7, 160)   480         ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 7, 7, 160)   480         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 7, 7, 160)   480         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 7, 7, 160)   480         ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 7, 7, 160)   480         ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 7, 7, 160)   480         ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 7, 7, 192)   576         ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 7, 7, 192)   576         ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 7, 7, 192)   576         ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 7, 7, 192)   576         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 7, 7, 192)   576         ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 7, 7, 192)   576         ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 7, 7, 192)   576         ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 7, 7, 192)   576         ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 7, 7, 192)   576         ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 7, 7, 192)   576         ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 7, 7, 192)   576         ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 7, 7, 192)   576         ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 7, 7, 192)   576         ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 7, 7, 192)   576         ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 37632)        0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1024)         38536192    ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 1024)         0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 7)            7175        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 47,518,631\n",
            "Trainable params: 38,543,367\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = create_final_model(pre_trained_model, last_output)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uthb5DxEJfeE",
        "outputId": "14dc5164-b3ec-4cd1-a44b-11f1b4176d93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "66/66 - 363s - loss: 2.5580 - accuracy: 0.3789 - val_loss: 1.1621 - val_accuracy: 0.5583 - 363s/epoch - 6s/step\n",
            "Epoch 2/50\n",
            "66/66 - 15s - loss: 1.2152 - accuracy: 0.5280 - val_loss: 0.9627 - val_accuracy: 0.6250 - 15s/epoch - 227ms/step\n",
            "Epoch 3/50\n",
            "66/66 - 15s - loss: 1.1018 - accuracy: 0.5714 - val_loss: 1.0770 - val_accuracy: 0.5917 - 15s/epoch - 223ms/step\n",
            "Epoch 4/50\n",
            "66/66 - 15s - loss: 1.0406 - accuracy: 0.5875 - val_loss: 0.9311 - val_accuracy: 0.6667 - 15s/epoch - 222ms/step\n",
            "Epoch 5/50\n",
            "66/66 - 15s - loss: 0.9995 - accuracy: 0.6180 - val_loss: 0.9764 - val_accuracy: 0.6667 - 15s/epoch - 223ms/step\n",
            "Epoch 6/50\n",
            "66/66 - 15s - loss: 0.9579 - accuracy: 0.6234 - val_loss: 0.8014 - val_accuracy: 0.7250 - 15s/epoch - 222ms/step\n",
            "Epoch 7/50\n",
            "66/66 - 15s - loss: 0.9305 - accuracy: 0.6532 - val_loss: 0.8496 - val_accuracy: 0.7167 - 15s/epoch - 221ms/step\n",
            "Epoch 8/50\n",
            "66/66 - 15s - loss: 0.8762 - accuracy: 0.6723 - val_loss: 0.7933 - val_accuracy: 0.7500 - 15s/epoch - 222ms/step\n",
            "Epoch 9/50\n",
            "66/66 - 15s - loss: 0.8710 - accuracy: 0.6631 - val_loss: 0.9007 - val_accuracy: 0.7000 - 15s/epoch - 221ms/step\n",
            "Epoch 10/50\n",
            "66/66 - 15s - loss: 0.8444 - accuracy: 0.6860 - val_loss: 0.8148 - val_accuracy: 0.7167 - 15s/epoch - 222ms/step\n",
            "Epoch 11/50\n",
            "66/66 - 15s - loss: 0.8336 - accuracy: 0.6891 - val_loss: 0.7955 - val_accuracy: 0.7333 - 15s/epoch - 222ms/step\n",
            "Epoch 12/50\n",
            "66/66 - 14s - loss: 0.7801 - accuracy: 0.7036 - val_loss: 0.9936 - val_accuracy: 0.6500 - 14s/epoch - 219ms/step\n",
            "Epoch 13/50\n",
            "66/66 - 15s - loss: 0.7731 - accuracy: 0.7120 - val_loss: 0.8125 - val_accuracy: 0.7167 - 15s/epoch - 222ms/step\n",
            "Epoch 14/50\n",
            "66/66 - 15s - loss: 0.7440 - accuracy: 0.7158 - val_loss: 0.8411 - val_accuracy: 0.7083 - 15s/epoch - 222ms/step\n",
            "Epoch 15/50\n",
            "66/66 - 15s - loss: 0.7905 - accuracy: 0.7021 - val_loss: 0.8796 - val_accuracy: 0.7083 - 15s/epoch - 221ms/step\n",
            "Epoch 16/50\n",
            "66/66 - 15s - loss: 0.7271 - accuracy: 0.7273 - val_loss: 0.9638 - val_accuracy: 0.7000 - 15s/epoch - 220ms/step\n",
            "Epoch 17/50\n",
            "66/66 - 15s - loss: 0.7511 - accuracy: 0.7158 - val_loss: 0.8164 - val_accuracy: 0.7500 - 15s/epoch - 223ms/step\n",
            "Epoch 18/50\n",
            "66/66 - 15s - loss: 0.7009 - accuracy: 0.7426 - val_loss: 0.8541 - val_accuracy: 0.7583 - 15s/epoch - 228ms/step\n",
            "Epoch 19/50\n",
            "66/66 - 15s - loss: 0.6917 - accuracy: 0.7517 - val_loss: 0.8643 - val_accuracy: 0.7333 - 15s/epoch - 222ms/step\n",
            "Epoch 20/50\n",
            "66/66 - 15s - loss: 0.7018 - accuracy: 0.7387 - val_loss: 0.8816 - val_accuracy: 0.7083 - 15s/epoch - 222ms/step\n",
            "Epoch 21/50\n",
            "66/66 - 15s - loss: 0.6558 - accuracy: 0.7502 - val_loss: 0.8280 - val_accuracy: 0.7417 - 15s/epoch - 221ms/step\n",
            "Epoch 22/50\n",
            "66/66 - 15s - loss: 0.6268 - accuracy: 0.7617 - val_loss: 0.7279 - val_accuracy: 0.8083 - 15s/epoch - 222ms/step\n",
            "Epoch 23/50\n",
            "66/66 - 15s - loss: 0.6354 - accuracy: 0.7586 - val_loss: 0.8167 - val_accuracy: 0.7750 - 15s/epoch - 222ms/step\n",
            "Epoch 24/50\n",
            "66/66 - 15s - loss: 0.6139 - accuracy: 0.7762 - val_loss: 0.7814 - val_accuracy: 0.7250 - 15s/epoch - 235ms/step\n",
            "Epoch 25/50\n",
            "66/66 - 14s - loss: 0.6364 - accuracy: 0.7594 - val_loss: 0.9163 - val_accuracy: 0.7083 - 14s/epoch - 220ms/step\n",
            "Epoch 26/50\n",
            "66/66 - 14s - loss: 0.6292 - accuracy: 0.7471 - val_loss: 0.8143 - val_accuracy: 0.7083 - 14s/epoch - 220ms/step\n",
            "Epoch 27/50\n",
            "66/66 - 14s - loss: 0.6389 - accuracy: 0.7487 - val_loss: 0.7865 - val_accuracy: 0.7500 - 14s/epoch - 220ms/step\n",
            "Epoch 28/50\n",
            "66/66 - 15s - loss: 0.6112 - accuracy: 0.7762 - val_loss: 0.8156 - val_accuracy: 0.7500 - 15s/epoch - 221ms/step\n",
            "Epoch 29/50\n",
            "66/66 - 15s - loss: 0.5925 - accuracy: 0.7830 - val_loss: 0.7654 - val_accuracy: 0.7250 - 15s/epoch - 222ms/step\n",
            "Epoch 30/50\n",
            "66/66 - 15s - loss: 0.5719 - accuracy: 0.7968 - val_loss: 0.8298 - val_accuracy: 0.7500 - 15s/epoch - 221ms/step\n",
            "Epoch 31/50\n",
            "66/66 - 15s - loss: 0.5503 - accuracy: 0.7914 - val_loss: 0.8543 - val_accuracy: 0.7500 - 15s/epoch - 220ms/step\n",
            "Epoch 32/50\n",
            "66/66 - 15s - loss: 0.5771 - accuracy: 0.7884 - val_loss: 0.9713 - val_accuracy: 0.7000 - 15s/epoch - 220ms/step\n",
            "Epoch 33/50\n",
            "66/66 - 15s - loss: 0.6056 - accuracy: 0.7800 - val_loss: 0.8926 - val_accuracy: 0.7667 - 15s/epoch - 221ms/step\n",
            "Epoch 34/50\n",
            "66/66 - 14s - loss: 0.5124 - accuracy: 0.8075 - val_loss: 0.8768 - val_accuracy: 0.7583 - 14s/epoch - 219ms/step\n",
            "Epoch 35/50\n",
            "66/66 - 15s - loss: 0.5544 - accuracy: 0.7892 - val_loss: 0.7544 - val_accuracy: 0.7833 - 15s/epoch - 224ms/step\n",
            "Epoch 36/50\n",
            "66/66 - 15s - loss: 0.5660 - accuracy: 0.8052 - val_loss: 0.8494 - val_accuracy: 0.7417 - 15s/epoch - 221ms/step\n",
            "Epoch 37/50\n",
            "66/66 - 15s - loss: 0.5643 - accuracy: 0.7937 - val_loss: 0.8663 - val_accuracy: 0.7583 - 15s/epoch - 221ms/step\n",
            "Epoch 38/50\n",
            "66/66 - 14s - loss: 0.5429 - accuracy: 0.8052 - val_loss: 0.8988 - val_accuracy: 0.7500 - 14s/epoch - 220ms/step\n",
            "Epoch 39/50\n",
            "66/66 - 14s - loss: 0.4959 - accuracy: 0.8128 - val_loss: 0.8504 - val_accuracy: 0.7667 - 14s/epoch - 220ms/step\n",
            "Epoch 40/50\n",
            "66/66 - 14s - loss: 0.5437 - accuracy: 0.7914 - val_loss: 0.8284 - val_accuracy: 0.7250 - 14s/epoch - 219ms/step\n",
            "Epoch 41/50\n",
            "66/66 - 15s - loss: 0.5117 - accuracy: 0.8083 - val_loss: 0.7381 - val_accuracy: 0.7750 - 15s/epoch - 220ms/step\n",
            "Epoch 42/50\n",
            "66/66 - 15s - loss: 0.4951 - accuracy: 0.8212 - val_loss: 0.7978 - val_accuracy: 0.7833 - 15s/epoch - 221ms/step\n",
            "Epoch 43/50\n",
            "66/66 - 15s - loss: 0.5181 - accuracy: 0.8144 - val_loss: 0.8056 - val_accuracy: 0.8000 - 15s/epoch - 220ms/step\n",
            "Epoch 44/50\n",
            "66/66 - 15s - loss: 0.4772 - accuracy: 0.8098 - val_loss: 0.7666 - val_accuracy: 0.7917 - 15s/epoch - 221ms/step\n",
            "Epoch 45/50\n",
            "66/66 - 15s - loss: 0.4672 - accuracy: 0.8388 - val_loss: 0.7975 - val_accuracy: 0.7833 - 15s/epoch - 222ms/step\n",
            "Epoch 46/50\n",
            "66/66 - 15s - loss: 0.4810 - accuracy: 0.8197 - val_loss: 0.7844 - val_accuracy: 0.7833 - 15s/epoch - 223ms/step\n",
            "Epoch 47/50\n",
            "66/66 - 14s - loss: 0.4557 - accuracy: 0.8342 - val_loss: 0.9096 - val_accuracy: 0.7583 - 14s/epoch - 219ms/step\n",
            "Epoch 48/50\n",
            "66/66 - 15s - loss: 0.4805 - accuracy: 0.8144 - val_loss: 0.8669 - val_accuracy: 0.7583 - 15s/epoch - 221ms/step\n",
            "Epoch 49/50\n",
            "66/66 - 15s - loss: 0.4564 - accuracy: 0.8212 - val_loss: 0.7202 - val_accuracy: 0.8250 - 15s/epoch - 222ms/step\n",
            "Epoch 50/50\n",
            "66/66 - 15s - loss: 0.4870 - accuracy: 0.8151 - val_loss: 0.7478 - val_accuracy: 0.8000 - 15s/epoch - 222ms/step\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_generator,\n",
        "                    validation_data = validation_generator,\n",
        "                    epochs = 50,\n",
        "                    verbose = 2,\n",
        "                    steps_per_epoch = train_generator.samples // train_generator.batch_size,\n",
        "                    validation_steps = validation_generator.samples // validation_generator.batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ENiJNSMaYKM2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "83219398-4a09-48a0-d7a2-367e0a712359"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "uploaded=files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  root_path = '/content/gdrive/My Drive/Capstone-Dataset/'\n",
        "  path = root_path + fn\n",
        "  img = image.load_img(path, target_size=(150, 150))\n",
        "  \n",
        "  x=image.img_to_array(img)\n",
        "  x /= 255\n",
        "  x=np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "  \n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  \n",
        "  print(classes[0])\n",
        "  \n",
        "  if max([classes[0][0], classes[0][1], classes[0][2], classes[0][3], classes[0][4], classes[0][5], classes[0][6]]) == classes[0][0]:\n",
        "    print(fn + \" is alopecia_areata\")\n",
        "  elif max([classes[0][0], classes[0][1], classes[0][2], classes[0][3], classes[0][4], classes[0][5], classes[0][6]]) == classes[0][1]:\n",
        "    print(fn + \" is dandruff\")\n",
        "  elif max([classes[0][0], classes[0][1], classes[0][2], classes[0][3], classes[0][4], classes[0][5], classes[0][6]]) == classes[0][2]:\n",
        "    print(fn + \" is folliculitis\")\n",
        "  elif max([classes[0][0], classes[0][1], classes[0][2], classes[0][3], classes[0][4], classes[0][5], classes[0][6]]) == classes[0][3]:\n",
        "    print(fn + \" is healthy_scalp\")\n",
        "  elif max([classes[0][0], classes[0][1], classes[0][2], classes[0][3], classes[0][4], classes[0][5], classes[0][6]]) == classes[0][4]:\n",
        "    print(fn + \" is psoriasis\")\n",
        "  elif max([classes[0][0], classes[0][1], classes[0][2], classes[0][3], classes[0][4], classes[0][5], classes[0][6]]) == classes[0][5]:\n",
        "    print(fn + \" is seborrheic_dermatitis\")\n",
        "  elif max([classes[0][0], classes[0][1], classes[0][2], classes[0][3], classes[0][4], classes[0][5], classes[0][6]]) == classes[0][6]:\n",
        "    print(fn + \" is tinea_capitis\")"
      ],
      "metadata": {
        "id": "KcUwGD_2N_cj",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bee92d92-fc12-4e14-d1b2-7801b05414de"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f87b8760-4879-4424-a12c-ff721dd62099\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f87b8760-4879-4424-a12c-ff721dd62099\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving alopecia.jpg to alopecia (7).jpg\n",
            "Saving alopecia2.jpg to alopecia2 (7).jpg\n",
            "Saving alopecia3.jpg to alopecia3 (7).jpg\n",
            "Saving dandruff (2).jpg to dandruff (2) (12).jpg\n",
            "Saving dandruff.jpg to dandruff (13).jpg\n",
            "Saving dandruff2.jpg to dandruff2 (7).jpg\n",
            "Saving dandruff3.jpg to dandruff3 (7).jpg\n",
            "Saving foli_alo.jpg to foli_alo (12).jpg\n",
            "Saving foli_pso.jpg to foli_pso (7).jpg\n",
            "Saving healthy.jpg to healthy (7).jpg\n",
            "Saving lichen1.jpg to lichen1 (17).jpg\n",
            "Saving pso.jpg to pso (14).jpg\n",
            "Saving pso1.jpg to pso1 (19).jpg\n",
            "Saving pso2.jpg to pso2 (11).jpg\n",
            "Saving sebo1.jpg to sebo1 (16).jpg\n",
            "Saving sebor.jpg to sebor (7).jpg\n",
            "Saving tinea.jpg to tinea (17).jpg\n",
            "Saving tinea2.jpg to tinea2 (7).jpg\n",
            "Saving tinea3.jpg to tinea3 (7).jpg\n",
            "[9.9999511e-01 9.6748591e-14 3.5123793e-14 4.6923093e-10 2.1964642e-15\n",
            " 1.6428354e-13 4.8779875e-06]\n",
            "alopecia.jpg is alopecia_areata\n",
            "[8.5442883e-01 7.3435808e-06 8.7761582e-04 8.0450810e-04 1.0476480e-06\n",
            " 8.3691317e-05 1.4379695e-01]\n",
            "alopecia2.jpg is alopecia_areata\n",
            "[1.5763735e-02 7.7268022e-01 1.7012318e-06 2.0577146e-01 1.9951173e-08\n",
            " 2.5122345e-06 5.7803169e-03]\n",
            "alopecia3.jpg is dandruff\n",
            "[1.4791167e-08 9.9728215e-01 1.1950373e-05 2.6799419e-06 1.0825895e-03\n",
            " 1.6000841e-03 2.0573583e-05]\n",
            "dandruff (2).jpg is dandruff\n",
            "[0.00113482 0.30517116 0.00108665 0.00236215 0.6435317  0.04144773\n",
            " 0.00526586]\n",
            "dandruff.jpg is psoriasis\n",
            "[6.7014075e-06 9.6638930e-01 2.8778572e-05 6.7863637e-04 3.7139703e-03\n",
            " 2.8885441e-02 2.9718608e-04]\n",
            "dandruff2.jpg is dandruff\n",
            "[2.7242725e-11 9.9567235e-01 5.2421938e-12 4.3277368e-03 3.5354011e-12\n",
            " 1.0453100e-08 1.0190344e-09]\n",
            "dandruff3.jpg is dandruff\n",
            "[0.02171984 0.00440291 0.44544548 0.00385768 0.09524377 0.4163986\n",
            " 0.01293172]\n",
            "foli_alo.jpg is folliculitis\n",
            "[3.2696224e-08 7.7687706e-10 9.9945039e-01 1.3637017e-08 3.0223180e-06\n",
            " 4.8202870e-04 6.4612927e-05]\n",
            "foli_pso.jpg is folliculitis\n",
            "[8.1372173e-06 3.8962064e-03 3.1529353e-08 9.9609333e-01 2.6215627e-09\n",
            " 1.1373083e-06 1.2854030e-06]\n",
            "healthy.jpg is healthy_scalp\n",
            "[0.00070163 0.350097   0.00706034 0.00839632 0.162512   0.46593428\n",
            " 0.00529837]\n",
            "lichen1.jpg is seborrheic_dermatitis\n",
            "[3.6649602e-03 3.2563612e-01 4.9910996e-05 6.7837508e-03 4.5076948e-01\n",
            " 1.5320729e-01 5.9888523e-02]\n",
            "pso.jpg is psoriasis\n",
            "[0.00316253 0.00485888 0.00903732 0.02850756 0.20018023 0.75244063\n",
            " 0.00181282]\n",
            "pso1.jpg is seborrheic_dermatitis\n",
            "[5.16010186e-05 3.39878425e-02 1.62528545e-01 3.63617612e-04\n",
            " 7.62959244e-03 7.81823635e-01 1.36151295e-02]\n",
            "pso2.jpg is seborrheic_dermatitis\n",
            "[0.00131358 0.02664264 0.35640225 0.00159744 0.04224722 0.53668696\n",
            " 0.03510998]\n",
            "sebo1.jpg is seborrheic_dermatitis\n",
            "[0.01159846 0.09003267 0.03260583 0.00541899 0.45383093 0.31956723\n",
            " 0.08694586]\n",
            "sebor.jpg is psoriasis\n",
            "[5.4140672e-02 6.1674771e-04 3.0017078e-03 3.4070828e-05 1.3473308e-04\n",
            " 8.2659104e-04 9.4124544e-01]\n",
            "tinea.jpg is tinea_capitis\n",
            "[6.95728604e-03 5.27862028e-07 8.60566786e-07 1.30177105e-08\n",
            " 1.15256917e-05 8.52436983e-07 9.93028939e-01]\n",
            "tinea2.jpg is tinea_capitis\n",
            "[4.5283101e-03 3.0506731e-04 3.2791853e-02 6.4790613e-05 2.8845204e-02\n",
            " 2.2412194e-02 9.1105253e-01]\n",
            "tinea3.jpg is tinea_capitis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__7Mb76wvVMs"
      },
      "outputs": [],
      "source": [
        "model.save(root_path + \"/model/{}\".format('Categorical-adam_default-Capstone-Project-C22PS22-fix'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "\n",
        "export_dir = 'saved_model/1'\n",
        "tf.saved_model.save(model, export_dir)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "tflite_model_file = pathlib.Path('./Categorical_Adam_fix.tflite')\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ],
      "metadata": {
        "id": "nQR5bid3848Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('Categorical_Adam_fix.h5')"
      ],
      "metadata": {
        "id": "QJT5sUGkHH4u"
      },
      "execution_count": 19,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Categorical_adam_default_Capstone_Project_C22PS22.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}